{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# instal required imports\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/maurice-herwig/wofa    \n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "!{sys.executable} -m pip install ipython\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Similarity Measure for Formal Languages Based on Convergent Geometric Series\n",
    "###  University of Kassel, Germany\n",
    "\n",
    "<ul>\n",
    "    <li>Florian Bruse</li>\n",
    "    <li><u>Maurice Herwig</u></li>\n",
    "    <li>Martin Lange</li>\n",
    "</ul>    \n",
    "\n",
    "### 26th International Conference on Implementation and Application of Automata  (CIAA'22).\n",
    "Rouen, June 28-July 1 2022\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# WoFA \n",
    "Weight of finite automata (WoFA).\n",
    "## Installation\n",
    "\n",
    "````bash\n",
    "pip install git+https://github.com/maurice-herwig/wofa\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Creating a Finite Automaton Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from wofa import FiniteAutomata\n",
    "from wofa import weight_diff, weight\n",
    "from wofa import Matrix\n",
    "from ipywidgets import interactive, IntSlider, FloatSlider, Layout, ToggleButtons, HBox\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Setting the alphabet.\n",
    "FiniteAutomata.set_alphabet({'a', 'b'})\n",
    "\n",
    "initial_states = {1}\n",
    "transitions = [(1, 'a', 2), (1, 'b', 1), (2, 'a', 2), (2, 'b', 3), (3, 'a', 3), (3, 'b', 3)]\n",
    "final_states = {3}\n",
    "\n",
    "target = FiniteAutomata(initial_states, transitions, final_states)\n",
    "\n",
    "submission = FiniteAutomata({1}, [(1, 'a', 2), (2, 'b', 3)], {3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def share_of_word_lengths(lam, lengths, eta):\n",
    "    shares = []\n",
    "    fac = ((1 - lam)/ lam)\n",
    "    \n",
    "    sum_to_eta = 0\n",
    "    \n",
    "    for i in lengths:\n",
    "        shares.append(lam**(i + 1) * fac)\n",
    "        \n",
    "        if i <= eta:\n",
    "            sum_to_eta += lam**(i + 1) * fac\n",
    "            \n",
    "    for i in range(eta + 1):\n",
    "        shares[i] = sum_to_eta / (eta + 1)\n",
    "        \n",
    "        \n",
    "    return shares\n",
    "        \n",
    "    \n",
    "def share_of_one_word(lam, lengths, eta):\n",
    "    shares = []\n",
    "    fac = ((1 - lam)/ lam)\n",
    "    \n",
    "    sum_w_c_p = 1 - lam ** (eta + 1)\n",
    "    \n",
    "    max_words_in_c_p = max_words_in_c_p = (1 - len(FiniteAutomata.get_alphabet()) ** (eta + 1)) / (1 - len(FiniteAutomata.get_alphabet()))\n",
    "\n",
    "    w_of_one_word_c_p = sum_w_c_p / max_words_in_c_p\n",
    "    \n",
    "\n",
    "    \n",
    "    for i in lengths:\n",
    "        shares.append(lam**(i + 1) * fac / (len(FiniteAutomata.get_alphabet())**i))\n",
    "        \n",
    "            \n",
    "    for i in range(eta + 1):\n",
    "        shares[i] = w_of_one_word_c_p\n",
    "        \n",
    "    return shares\n",
    "    \n",
    "    \n",
    "def weight_calc_lam(lam):\n",
    "    lengths = [i for i in range(11)]\n",
    "    \n",
    "    shares = share_of_word_lengths(lam, lengths, 0)\n",
    "    \n",
    "    plt.bar(lengths, shares)\n",
    "    \n",
    "    plt.ylabel('share')\n",
    "    plt.xlabel('word length')\n",
    "    #plt.title('Distribution of the proportions of the share length to the total weight')\n",
    "    plt.ylim([0, shares[0]+shares[0] * 0.1])\n",
    "    \n",
    "    \n",
    "    weight = weight_diff(target, submission, 0, lam)[2]\n",
    "    \n",
    "    plt.show()\n",
    "    l_t = '$L_{target}$'\n",
    "    l_s = '$L_{submission}$'\n",
    "    display(Markdown(f'<span class=\"outputText\">Distance between {l_t} and {l_s}: {round(weight, 3)}</span>'))\n",
    "    \n",
    "def weight_calc_eta_and_lam(lam, eta):\n",
    "    lengths = [i for i in range(11)]\n",
    "    \n",
    "    \n",
    "    shares = share_of_one_word(lam, lengths, eta)\n",
    "\n",
    "    plt.bar(lengths, shares)\n",
    "    \n",
    "    plt.ylabel('weight of one word')\n",
    "    plt.xlabel('word length')\n",
    "    #plt.title('Distribution of the proportions of the share length to the total weight')\n",
    "    plt.ylim([0, shares[0]+ shares[0] * 0.1])\n",
    "    \n",
    "    weight = weight_diff(target, submission, eta, lam)[2]\n",
    "    \n",
    "    plt.show()\n",
    "    l_t = '$L_{target}$'\n",
    "    l_s = '$L_{submission}$'\n",
    "    display(Markdown(f'<span class=\"outputText\">Distance between {l_t} and {l_s}: {round(weight, 3)}</span>'))\n",
    "    \n",
    "def fractions(n, button):\n",
    "    # geht nur fÃ¼r n >= 1 \n",
    "    x = 21\n",
    "    lam = 0.5\n",
    "\n",
    "    transitions = [ (i, a, (i + 1) % n) for i in range(n) for a in FiniteAutomata.get_alphabet()]\n",
    "    transitions.append((n , 'a', 0))\n",
    "\n",
    "    language = FiniteAutomata({n}, transitions, {0})\n",
    "    matrix = Matrix(language)\n",
    "\n",
    "\n",
    "    lengths = [i for i in range(x)]\n",
    "    shares = share_of_word_lengths(lam, lengths, 0)\n",
    "    fraction = [matrix.get_share(i) * shares[i] for i in range(x)]\n",
    "\n",
    "\n",
    "    bar1 = plt.bar(lengths, shares)\n",
    "    bar2 = plt.bar(lengths, fraction)\n",
    "    plt.legend([bar1, bar2], ['$\\omega_{0.5}(\\Sigma^n)$', '$f_{L_j}(n) \\cdot \\omega_{0.5}(\\Sigma^n)$'], \n",
    "               prop={'size': 18})\n",
    "    \n",
    "    plt.ylabel('share')\n",
    "    if button == 'log-scale':\n",
    "        plt.yscale('log')\n",
    "        \n",
    "    plt.xlabel('word length')\n",
    "    #plt.title('Weighting of the word lengths with inclusion of the fraction.')\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    display(Markdown(f'<span class=\"outputText\">Weight of the example language: {round(weight(language, 0, 0.5), 3)}</span>'))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "- **Distance measure between regular languages**\n",
    "\n",
    "- For automatic feedback / grading on the solutions of students.\n",
    "    - Evaluation of the <span style=\"color:red\">semantic error</span> instead of the syntactic error. \n",
    "    \n",
    "- Other fields of application:  image processing, bioinformatics, data science, etc.\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h1 style=\"margin-buttom: 0\"> Problems with other distance measures</h1>\n",
    "<h3 style=\"margin: 0\"> Word distance  induces a distance on languages</h3>\n",
    "    \n",
    " $$\\hat{d}(L_1,L_2) := \\min \\{ d(w_1,w_2) \\mid w_i \\in L_i \\}$$\n",
    "\n",
    "- For typical distance types $d$: Euclidian, Manhattan, Cosine, Hamming, Levenshtein, etc.\n",
    "- Ignores the <span style=\"color:red\">inner structure</span> of these languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3 style=\"margin: 0\">Hausdorff distance</h3>\n",
    "\n",
    "\n",
    "$$ \\hat{d}(L_1, L_2) = \\max \\big(\\{ \\tilde{d}(L_1, w) \\mid w \\in L_2 \\} \\cup \\{ \\tilde{d}(L_2, w') \\mid w' \\in L_1\\} \\big) \\\\\n",
    "\\text{ where }\\tilde{d}(L,w) = \\min \\{d(w',w) \\mid w' \\in L\\}\n",
    "$$\n",
    "\n",
    "<ul><li><span style=\"color:red\">Undecidability problems</span> by using this definition ([Choffrut and Pighizzini, 2002]).\n",
    "    </li></ul>\n",
    "\n",
    "<h3 style=\"margin-buttom: 0\">Weighting of the symmetrical difference $L_1 \\triangle L_2$</h3>\n",
    "\n",
    "<ul>\n",
    "    <li>$L_1 \\triangle L_2$ can be infinite.</li>\n",
    "    <li><span style=\"color:red\">Limit value</span> of the fraction of words per word length <span style=\"color:red\">does not have to exist</span> \n",
    "        ([Alur et al., 2013]).</li>\n",
    "</ul>\n",
    "    \n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "<h3 style=\"margin-buttom: 0\">Solution</h3>\n",
    "<ul>\n",
    "    <li>Word lengths, <span style=\"color:red\">descending weight</span> by using the <span style=\"color:red\">geometric series.</span></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weight of a Language\n",
    "\n",
    "Let $L \\subseteq \\Sigma^*$ and $L^{n} = \\{w \\mid w \\in L  $ and $|w| = n \\}$. \n",
    "\n",
    "Let $f_L\\colon\\mathbb{N}\\to[0,1]$ be the <span style=\"color:red\">fraction of words</span> from $\\Sigma^n$ that are in $L$.\n",
    "\n",
    "$$f_L(n) = \\frac{|L^{n}|}{|\\Sigma^n|}$$\n",
    "\n",
    "The $\\lambda \\in (0,1)$ <span style=\"color:red\">weight of a language</span>\n",
    "$\\omega_\\lambda\\colon2^{\\Sigma^*} \\to [0,1]$ can be determined as follows. \n",
    "\n",
    "$$\\omega_\\lambda(L) = (1-\\lambda) \\cdot \\sum_{i = 0}^{\\infty} \\lambda^i \\cdot f_L(i) \n",
    "= (1-\\lambda) \\cdot \\sum_{i=0}^{\\infty} \\lambda^i \\cdot \\frac{|L^{i}|}{|\\Sigma^i|}$$\n",
    "\n",
    "\n",
    "$\\Rightarrow$ For all $\\lambda \\in (0,1)$: $\\omega_\\lambda$ is monotonic, $\\omega_\\lambda(\\emptyset) = 0$ and $ \\omega_\\lambda( \\Sigma^*) = 1 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_j = a\\Sigma^j$ with $\\Sigma = \\{a, b\\}$ and $\\lambda = 0.5$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "interactive(\n",
    "    fractions,\n",
    "    n = IntSlider(value= 2, min= 1, max= 10, layout=Layout(width='500px'), description=r'\\(\\ j\\)'),\n",
    "    button = ToggleButtons(options=['lin-scale', 'log-scale'], description=\" \"),\n",
    ")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# For a DFA the weight is computable\n",
    "\n",
    "<span class=\"Theorem\">**Theorem.**  $\\omega_\\lambda(L(\\mathcal{A}))$ is computable if $\\mathcal{A} = (Q, \\Sigma, \\delta, q_i, Q_F)$ is a  <span style=\"color:red\">DFA.</span> </span>\n",
    "\n",
    "\n",
    "**Proof-idea:**\n",
    "\n",
    "For $q \\in Q$, let $L_q = L(\\mathcal{A}_q)$ with $\\mathcal{A}_q = (Q, \\Sigma, \\delta, q,$ $Q_F)$ and the weight. \n",
    "\n",
    "$$\\omega_\\lambda(L_q) = (1-\\lambda) \\cdot \\sum_{i=0}^{\\infty} \\lambda^i \\cdot \\frac{|L_q^{i}|}{|\\Sigma^i|}\\ $$ \n",
    "\n",
    "\n",
    "By using the transitions, the weights of the languages can be determined recursively.  \n",
    "\n",
    "$$(1-\\lambda) \\cdot |L_q^{0}| +  \\frac{\\lambda}{|\\Sigma|}  \\cdot \\sum_{a \\in \\Sigma} \\omega_\\lambda(L_{\\delta(q,a)})  $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- $ t_{q,q'}=\\frac{|\\{ a \\in \\Sigma \\mid \\delta(q, a) = q' \\}|}{|\\Sigma|}$ \n",
    "- $e_q = 1 \\text{ if }q \\in Q_F \\text{ and }e_q = 0 \\text{ otherwise } $\n",
    "\n",
    "So we can write $\\omega_\\lambda(L_q)$ as:\n",
    "\n",
    "$$\\omega_\\lambda(L_q) = (1-\\lambda) \\cdot e_q + \\lambda \\cdot t_{q,q_1} \\omega_\\lambda(L_{q_1}) + \\dotsb + \\lambda \\cdot t_{q,q_n} \\omega_\\lambda(L_{q_n})$$\n",
    "\n",
    "This results in an equation system:\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    " - (1-\\lambda) \\cdot e_{q_1} &=  (\\lambda \\cdot t_{q_1,q_1} -1) \\cdot \\omega_\\lambda(L_{q_1}) + \\dotsb +  \\lambda \\cdot t_{q_1,q_n}\\cdot  \\omega_\\lambda(L_{q_n}) \\\\\n",
    "\\vdots \\quad & \\quad \\quad \\quad \\quad \\quad \\quad \\vdots \\quad \\quad \\quad \\quad \\ddots\\quad  \\quad \\quad \\quad  \\vdots \\\\\n",
    " - (1-\\lambda) \\cdot e_{q_n} &= \\ \\ \\ \\ \\ \\quad \\lambda \\cdot t_{q_n,q_1} \\cdot \\omega_\\lambda(L_{q_1}) + \\dotsb +  (\\lambda \\cdot t_{q_n,q_n}-1) \\cdot \\omega_\\lambda(L_{q_n}) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "There is exactly a <span style=\"color:red\">unique solution</span> for the system of equations and: \n",
    "\n",
    "$$\\omega_\\lambda(L) = \\omega_\\lambda(L_{q_i}) $$\n",
    "\n",
    "$\\Rightarrow \\omega_\\lambda(L(\\mathcal{A}))$ is computable in time $\\mathcal{O}(n^3)$ for a DFA with $n$ states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Distance of two Languages\n",
    "\n",
    "**Aim**: weight function $\\rightarrow$ distance function.\n",
    "\n",
    "<span style=\"color:red\">Distance of two languages</span> $d_\\lambda \\colon 2^{\\Sigma^*} \\times 2^{\\Sigma^*} \\to [0,1]$ \n",
    "\n",
    "can be determined by the <span style=\"color:red\">symmetric difference</span> $L_1 \\triangle L_2$.\n",
    "\n",
    "$$d_\\lambda(L_1, L_2) = \\omega_\\lambda(L_1 \\triangle L_2)$$\n",
    "\n",
    "\n",
    "<span  class=\"Theorem\" >**Theorem.** $d_\\lambda$ is a metric on the space of all $\\Sigma$-languages.</span>\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "**Proof:**\n",
    "<ul style=\"margin: 0;\">\n",
    "    <li> $d_\\lambda(L_1, L_2) = 0$ iff $L_1 = L_2$: follow from $\\omega_\\lambda(\\emptyset) = 0$.</li>\n",
    "    <li>$d_\\lambda(L_1, L_2) = d_\\lambda(L_1, L_2)$: follow from $L_1 \\triangle L_2 = L_2 \\triangle L_1$.</li>\n",
    "    <li>$d_\\lambda(L_1, L_3) \\le d_\\lambda(L_1, L_2) + d_\\lambda(L_2, L_3)$: follow from if $w \\in L_1 \\triangle L_3$ then holds $w \\in L_1 \\triangle L_2$ or $w \\in L_2 \\triangle L_3$.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical application\n",
    "\n",
    "### students evaluation\n",
    "\n",
    "Implementation: https://github.com/maurice-herwig/wofa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical application\n",
    "\n",
    "**Recap motivation**: automatic feedback / grading  on the solutions of the students.\n",
    "   \n",
    "- Standard exercise: construct an automaton that recognizes exactly a given language.\n",
    "\n",
    "- Automatic feedback initiates an <span style=\"color:red\">error-driven learning cycle.</span>\n",
    "\n",
    "\n",
    "<h1 style=\"margin-buttom: 0\">Good parameter values?</h1>\n",
    "\n",
    "- For feedback / grading to the students solution.\n",
    "\n",
    "- For this we consider the difference of the following **example** languages over $\\Sigma = \\{a, b\\}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}& L_{target} = \\{w \\in \\Sigma^* \\mid w \\text{ contains the subword } ab\\} \\\\\n",
    "                & L_{submission}  = \\{ab \\}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$L_{target} = \\{w \\in \\Sigma^* \\mid w \\text{ contains the subword } ab\\}$ and $L_{submission} = \\{ab\\}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "interactive(\n",
    "    weight_calc_lam,\n",
    "    lam = FloatSlider(value=0.5, min=0.1, max=0.9, layout=Layout(width='500px'), description=r'\\(\\lambda\\)'),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Redistribution of Weights on Short Words\n",
    "\n",
    "<h3 style=\"margin-top: 20px\">Problem $\\lambda$</h3>\n",
    "$\\omega_\\lambda$  results in a strong <span style=\"color:red\">overweighting</span> of <span style=\"color:red\">short word</span> lengths.\n",
    "\n",
    "- $\\eta$ near to $1$ flatten the distribution curve, but this is not a got distribution over the length. \n",
    "\n",
    "- Does not lead to good results.\n",
    "\n",
    "<h3 style=\"margin-top: 20px\">Solution: parameter $\\eta$</h3>\n",
    "\n",
    "- Words with length <span style=\"color:red\">up to</span> a certain length $\\eta$ should be weighted <span style=\"color:red\">equally.</span>\n",
    "\n",
    "- Word with length <span style=\"color:red\">greater</span> than $\\eta$ should be weighted <span style=\"color:red\">exponentially decreasing.</span>\n",
    "\n",
    "$$\\omega_\\lambda^\\eta(L) = \\omega'_\\lambda(L^{(\\le \\eta)}) + \\omega_\\lambda(L^{(> \\eta)})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\omega_\\lambda^\\eta(L) = \\omega'_\\lambda(L^{(\\le \\eta)}) + \\omega_\\lambda(L^{(> \\eta)})$$\n",
    "\n",
    "\n",
    "<span class=\"Theorem\">**Theorem.**  $\\omega_\\lambda^\\eta(L)$ is computable. </span>\n",
    "\n",
    "**Proof-idea:**\n",
    "\n",
    "- $\\omega'_\\lambda(L^{(\\le \\eta)})$ by <span style=\"color:red\"> matrix multiplication.</span>\n",
    "     - $A^1$ = Adjacency matrix of $\\delta$.\n",
    "     - $A^i = A^{i-1} \\cdot A^1$\n",
    "     - Weight of one word $\\frac{1-\\lambda^{\\eta+1}}{\\sum_{i=0}^{\\eta} |\\Sigma|^i}$.\n",
    "\n",
    "- $\\omega_\\lambda(L^{(> \\eta)}) = \\omega_\\lambda(L) - \\omega_\\lambda(L^{(\\le \\eta)})$\n",
    "\n",
    "$\\Rightarrow \\omega'_\\lambda(L^{(\\le \\eta)})$ is computable in time $\\mathcal{O}(\\eta \\cdot |Q|^3)$.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "$L = \\{w \\in \\{a, b\\}^* \\mid w \\text{ not contains the subword } abba\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interactive(\n",
    "    weight_calc_eta_and_lam,\n",
    "    lam = FloatSlider(value=0.7, min=0.1, max=0.9, layout=Layout(width='500px'), description=r'\\(\\lambda\\)'),\n",
    "    eta = IntSlider(value= 4, min= 0, max= 10, layout=Layout(width='500px'), description=r'\\(\\eta\\)')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good parameter values:** $\\eta$ = pumping constant, $\\lambda$ so that $\\omega'_\\lambda(\\Sigma^{*^{(\\le \\eta)}}) = \\omega_\\lambda(\\Sigma^{*^{(> \\eta)}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- <span style=\"color:red\">Weight function</span> for regular languages.\n",
    "    - Well defined by using the geometric series.\n",
    "- <span style=\"color:red\">Distance measure</span> between two regular languages.\n",
    "    - By the determinations of the weight of the symmetrical difference.\n",
    "- <span style=\"color:red\">Practical use</span> for students evaluation.\n",
    "    - Initial part with constant weighting of words.\n",
    "\n",
    "<h3 style=\"margin-bottom: 0\">Currently work</h3>\n",
    "\n",
    "- Web page for automatic correction of student submissions by the distance measure. \n",
    "\n",
    "<h3 style=\"margin-bottom: 0\">Open work</h3>\n",
    "\n",
    "- Is it possible to calculate the distance between two NFA without explicit determination?\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {}
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
